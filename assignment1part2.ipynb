{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeHRxmOCw6PgY3+kuOWmC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtminnick/pytorch-practice/blob/main/assignment1part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Learning - Manually Graded Assignment 1 - Part 2 (CIFAR Dataset)**\n",
        "\n",
        "Donnie Minnick\n",
        "\n",
        "October 2025"
      ],
      "metadata": {
        "id": "TZCVLAIIwVlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "ZQxh3j8UwpvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "cLTm1HJgwskp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load CIFAR Data"
      ],
      "metadata": {
        "id": "imq7zgUIwyN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Get training data.\n",
        "\n",
        "training_data = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                             train = True,\n",
        "                                             download = True,\n",
        "                                             transform = transform)\n",
        "\n",
        "# Get testing data.\n",
        "\n",
        "testing_data = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                            train = False,\n",
        "                                            download = True,\n",
        "                                            transform = transform)\n"
      ],
      "metadata": {
        "id": "QTTuNArIw37e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm download of training data."
      ],
      "metadata": {
        "id": "AAk5VDeJx7Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set size:\", len(training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjMr0MHGx9M8",
        "outputId": "ba6b6ee6-7776-49d3-f166-9293dcd6981b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm download of testing data."
      ],
      "metadata": {
        "id": "tBt3KVR9yABz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing set size:\", len(testing_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkFeJ2hdyCOS",
        "outputId": "63737ae2-5823-4cfc-cb0f-f2c8834e4ba7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing set size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data\n",
        "\n",
        "Split the data into training, validation and testing sets.\n",
        "\n",
        "A testing set already exists; randomly take 10,000 images from the training set and reserve them as a validation set."
      ],
      "metadata": {
        "id": "XjeXe4deyT7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 40000\n",
        "val_size = 10000\n",
        "\n",
        "training_data, validation_data = random_split(training_data, [train_size, val_size])"
      ],
      "metadata": {
        "id": "u4CuVzycyZVU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm splits."
      ],
      "metadata": {
        "id": "8MDt9kdjymWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set size:\", len(training_data))\n",
        "print(\"Validation set size:\", len(validation_data))\n",
        "print(\"Testing set size:\", len(testing_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvhAIvH6ynva",
        "outputId": "2f97b34f-266a-4b50-b986-4572d878d1d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 40000\n",
            "Validation set size: 10000\n",
            "Testing set size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a CNN Network\n",
        "\n",
        "Build a CNN network with convolution layers to classify the images."
      ],
      "metadata": {
        "id": "kWEGYGufysJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Data Loaders\n",
        "\n",
        "Batch training and validation data with batch_size = 64. Shuffle training data for generalization; validation data is not shuffled, ensuring consistent evaluation."
      ],
      "metadata": {
        "id": "qI3is047y44C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "training_loader = DataLoader(training_data, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "validation_loader = DataLoader(validation_data, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "testing_loader = DataLoader(testing_data, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "SIOpRdWFy8Jp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}